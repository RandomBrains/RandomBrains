# 👩‍💻 Hi, I'm Random Brain

🎓 Independent Researcher | AI Safety | Multilingual Evaluation | Prompt Engineering  
🌍 Exploring model robustness, hallucination detection, and alignment in diverse languages

---

## 🔍 About Me | 关于我

I am an independent researcher with a focus on the safe and interpretable deployment of large language models (LLMs) in multilingual, high-stakes environments such as healthcare, law, and education. My research combines adversarial evaluation, prompt engineering, and multilingual corpus analysis.

我是⼀名独立研究者，关注⼤型语言模型（LLMs）在医疗、法律、教育等关键多语环境中的安全与可解释部署。我的研究方向包括对抗性评估、提示工程和多语言语料分析。

---

## 🧪 Projects | 项目一览

🔬 [MASB (Multilingual Adversarial Safety Benchmark)](https://github.com/RandomBrains/MASB)  
Benchmarks LLM behavior across languages using adversarial prompts  
多语言对抗性安全评估基准，用于测试 LLM 在不同语言下的幻觉与拒答行为

📊 [LLM Risk Visualizer](https://github.com/RandomBrains/LLM-Risk-Visualizer)  
An interactive Streamlit tool for visualizing hallucination and refusal rates  
交互式可视化工具，分析 LLM 的幻觉与拒答风险

🧠 [Prompt Engineering Toolkit (PET)](https://github.com/RandomBrains/Prompt-Engineering-Toolkit)  
Curated jailbreak prompts and test suite for alignment & robustness  
提示攻击与对齐测试工具包，用于模型红队测试与稳健性分析

---

## 🌐 Contact & Info | 联系方式

- 📧 Email: randombrain489@gmail.com  
- 🧬 GitHub: [@RandomBrains](https://github.com/RandomBrains)  
- 📅 Birthday: July 23, 1985  
- 🌍 Languages: English, 中文, Deutsch  
